# Self and World: The Foundational Abstraction

## A Framework for Understanding Neural Organization of Abstract Concepts

**Hillary Danan, PhD**  
Cognitive Neuroscience

*Working Draft — December 2025*

-----

## Abstract

Why does the brain organize abstract concepts along a dimension of internal-to-self versus external-to-self? Empirical research demonstrates that neural representations of abstract concepts systematically vary according to their relationship to the self — concepts like *pride* and *guilt* activate distinct networks from concepts like *gravity* and *distance*. This paper proposes that this organization is not arbitrary but computationally necessary. Drawing on the Abstraction Primitive Hypothesis (Danan, 2025), I argue that **self versus not-self constitutes the foundational abstraction** — the first distinction any intelligent system embedded in an environment must make. This framework explains empirical findings in abstract concept representation, connects to theories of embodied and grounded cognition, and generates testable predictions about the developmental and computational priority of self-referential abstraction.

-----

## 1. Introduction

Abstract concepts present a puzzle for cognitive science. Unlike concrete concepts (*apple*, *chair*), which can be grounded in sensorimotor experience, abstract concepts (*justice*, *entropy*, *pride*) lack direct perceptual referents. Yet humans acquire, represent, and reason with abstract concepts fluently. How?

Empirical research has revealed that the brain does not treat all abstract concepts uniformly. Neural representations of abstract concepts organize along systematic dimensions, including a prominent dimension distinguishing **internal-to-self** concepts (emotions, mental states, self-evaluations) from **external-to-self** concepts (physical forces, spatial relations, environmental properties) (Binder et al., 2016; Borghi et al., 2017; Villani et al., 2019).

This paper asks: **why this organization?**

The Abstraction Primitive Hypothesis (APH) proposes that abstraction — the extraction of invariant structure across instances — is the fundamental operation underlying intelligence (Danan, 2025a). If abstraction is primitive, then the dimensions along which abstractions organize should reflect computational necessities, not arbitrary conventions.

I propose that **self versus not-self is the foundational abstraction** — the first distinction an embedded intelligent system must make, and the scaffolding upon which all subsequent abstractions build.

-----

## 2. Empirical Background: Neural Organization of Abstract Concepts

### 2.1 The Heterogeneity of Abstract Concepts

Early theories treated abstract concepts as a monolithic category defined by what they lack — perceptual grounding (Paivio, 1986). Contemporary research reveals that abstract concepts are heterogeneous, varying along multiple dimensions (Borghi et al., 2017).

Key dimensions identified in the literature include:

- **Emotional valence and arousal** (Kousta et al., 2011; Vigliocco et al., 2014)
- **Social content** (Arioli et al., 2021)
- **Interoceptive grounding** (Connell et al., 2018)
- **Self-relevance** (Northoff et al., 2006; Kelley et al., 2002)

### 2.2 The Self-Relevance Dimension

A robust finding across neuroimaging studies is that concepts varying in self-relevance recruit distinct neural systems:

**Internal-to-self concepts** (e.g., *pride*, *guilt*, *agency*, *intention*) reliably activate:

- Medial prefrontal cortex (mPFC)
- Posterior cingulate cortex (PCC)
- Temporoparietal junction (TPJ)

This network overlaps substantially with the “default mode network” and regions implicated in self-referential processing (Northoff et al., 2006; Andrews-Hanna et al., 2014).

**External-to-self concepts** (e.g., *gravity*, *velocity*, *distance*, *causation*) show greater reliance on:

- Lateral prefrontal and parietal regions
- Sensorimotor simulation areas
- Systems involved in physical reasoning (Fischer et al., 2016)

This dissociation is not reducible to concreteness. *Gravity* is abstract (you cannot point to gravity itself, only its effects), yet it patterns with external-world concepts. *Pride* involves bodily feelings, yet it patterns with internal-self concepts.

### 2.3 Developmental Evidence

The self/world distinction emerges early. Infants distinguish self-generated from externally-generated motion by 3-4 months (Rochat, 1998). The capacity for mirror self-recognition — requiring a self-concept — emerges around 18 months and correlates with subsequent development of abstract self-evaluative concepts (Lewis, 2011).

This developmental priority suggests the self/world boundary may serve as scaffolding for subsequent conceptual organization.

-----

## 3. Theoretical Framework: Why Self/Not-Self Must Be Foundational

### 3.1 The Abstraction Primitive Hypothesis

The Abstraction Primitive Hypothesis (APH) proposes:

> Intelligence, across substrates, is the capacity to form, store, retrieve, and compose abstractions. Abstraction — the extraction of invariant structure across variable instances — is the primitive operation from which other cognitive operations derive.

If abstraction is primitive, then the *first* abstractions a system forms should be those most necessary for survival and function. What must any embedded intelligent system distinguish first?

### 3.2 The Computational Necessity Argument

Consider any system that:

1. Is embedded in an environment
1. Must act to survive
1. Receives sensory input and produces motor output

Such a system faces an immediate computational problem: **distinguishing what it controls from what it does not control.**

- Motor commands produce predictable consequences (when I move my arm, proprioceptive feedback follows)
- Environmental events produce unpredictable consequences (when a branch falls, I must react)

This is not a philosophical distinction but a computational one. Effective action requires predicting the consequences of one’s own actions (forward models), which requires distinguishing self-caused from world-caused events (Wolpert & Ghahramani, 2000; Friston, 2010).

**Hypothesis 1:** The self/not-self abstraction is computationally prior — it must be established before other abstractions can be reliably formed, because other abstractions require knowing which regularities reflect the system’s own actions versus environmental structure.

### 3.3 Grounding Abstraction in Embodiment

Embodied cognition theories propose that even abstract concepts are grounded in sensorimotor and interoceptive experience (Barsalou, 2008; Lakoff & Johnson, 1999). The present framework specifies *how* this grounding is organized:

**External-to-self concepts** ground in:

- Exteroception (vision, audition, touch as contact with world)
- Sensorimotor contingencies with the environment
- Regularities that persist regardless of the system’s actions

**Internal-to-self concepts** ground in:

- Interoception (internal body states)
- Sense of agency (the experience of causing actions)
- Regularities that depend on the system’s own states and actions

Gravity exemplifies external grounding: it acts on the self constantly, unchangeably, regardless of intention. The abstraction *gravity* captures the invariant structure of this ever-present external force.

Pride exemplifies internal grounding: it arises from self-evaluation against self-generated standards. The abstraction *pride* captures invariant structure across instances of positive self-assessment.

### 3.4 Connection to Self-Referential Computation

The Abstraction-Intelligence framework’s third paper (Danan, 2025c) argues that consciousness emerges when abstraction is applied reflexively — when a system models itself as part of its world model.

The self/world distinction is the *precondition* for this reflexive move. A system cannot model itself until it has distinguished itself from not-self. The internal-to-self dimension of abstract concept organization may therefore reflect the architecture required for self-modeling.

**Hypothesis 2:** The neural systems supporting internal-to-self concepts (mPFC, PCC, TPJ) are the same systems required for recursive self-modeling because self-referential abstraction is what these systems *compute*.

-----

## 4. Integration: From Empirical Pattern to Theoretical Explanation

The proposed framework offers a parsimonious explanation for the empirical organization of abstract concepts:

|Empirical Finding                                                            |Theoretical Explanation                                                                         |
|-----------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|
|Abstract concepts organize along self-relevance dimension                    |Self/not-self is the foundational abstraction; all subsequent abstractions inherit this scaffold|
|Internal-to-self concepts recruit default mode network                       |DMN computes self-referential abstractions; internal concepts require this computation          |
|External-to-self concepts recruit sensorimotor and physical reasoning systems|External concepts ground in world-regularities processed by these systems                       |
|Self-relevance dimension emerges early in development                        |Foundational abstractions must be established before derived abstractions                       |
|Distinction is not reducible to concreteness                                 |The relevant dimension is computational (self vs. world), not perceptual (concrete vs. abstract)|

-----

## 5. Predictions

The framework generates falsifiable predictions:

### 5.1 Developmental Predictions

**Prediction 1:** Disruption of self/other distinction in infancy (e.g., through aberrant sensorimotor contingencies) should produce downstream deficits in organizing *all* abstract concepts, not just self-referential ones.

**Prediction 2:** The developmental trajectory of abstract concept acquisition should show self-referential concepts (internal-to-self) and physical concepts (external-to-self) emerging before concepts that require integrating both (e.g., *fairness*, which requires modeling both self-interest and external social structure).

### 5.2 Neural Predictions

**Prediction 3:** Lesions to medial prefrontal structures should impair internal-to-self abstract concepts more than external-to-self concepts, even when controlling for emotional content.

**Prediction 4:** Individual differences in interoceptive accuracy should correlate with richness of internal-to-self abstract concept representations but not external-to-self representations.

### 5.3 Computational Predictions

**Prediction 5:** Artificial systems trained without self/world distinction (no forward model, no sense of agency) should show impaired transfer learning on tasks requiring abstract reasoning, because they lack the foundational scaffold.

**Prediction 6:** In neural networks, representational similarity analysis should reveal that the self/world distinction (where applicable) accounts for more variance in abstract concept organization than concreteness or imageability.

-----

## 6. Relation to Existing Theories

### 6.1 Grounded Cognition

The present framework is compatible with grounded cognition (Barsalou, 2008) but adds specificity: grounding is organized around the self/world boundary because this boundary is computationally foundational.

### 6.2 Predictive Processing

Predictive processing frameworks (Clark, 2013; Friston, 2010) emphasize the brain’s task of predicting sensory input. The self/world distinction is essential to this task — predicting the consequences of one’s own actions (agency) requires different computations than predicting external events. The present framework proposes that this computational distinction shapes abstract concept organization.

### 6.3 Interoceptive Inference

Seth and colleagues propose that selfhood emerges from interoceptive inference — the brain’s modeling of internal bodily states (Seth, 2013; Seth & Friston, 2016). The present framework extends this: interoceptive inference grounds the internal-to-self dimension of abstract concepts, while exteroceptive inference grounds the external-to-self dimension.

-----

## 7. Limitations and Open Questions

### 7.1 Concepts That Span the Boundary

Some abstract concepts resist clean categorization. *Fairness* involves both self-interest (internal) and social structure (external). *Time* is experienced internally but structures external events. The framework predicts these concepts should show mixed neural signatures and develop later — but this requires empirical test.

### 7.2 Cultural Variation

The self/world boundary may be construed differently across cultures (Markus & Kitayama, 1991). Does this affect abstract concept organization? The framework predicts the *computational* distinction is universal, but its *boundaries* may shift — a testable hypothesis.

### 7.3 The Hard Problem

This framework addresses the *organization* of concepts, not the phenomenology of self-experience. Why self-modeling feels like something remains unaddressed (Chalmers, 1995). The framework is compatible with multiple positions on phenomenal consciousness.

-----

## 8. Conclusion

Why does the brain organize abstract concepts along a self-relevance dimension? Because **self versus not-self is the foundational abstraction** — the first distinction an embedded intelligent system must make, and the scaffold upon which subsequent abstractions build.

This proposal:

- **Explains** empirical findings on neural organization of abstract concepts
- **Connects** grounded cognition, predictive processing, and interoceptive inference
- **Extends** the Abstraction Primitive Hypothesis to conceptual organization
- **Generates** falsifiable predictions about development, neural implementation, and computation

Gravity grounds us physically. The abstraction of *gravity* — as external-to-self — grounds us conceptually. The self/world boundary is where intelligence begins.

-----

## References

Andrews-Hanna, J. R., Smallwood, J., & Spreng, R. N. (2014). The default network and self-generated thought: Component processes, dynamic control, and clinical relevance. *Annals of the New York Academy of Sciences*, 1316(1), 29-52.

Arioli, M., Bello, A., & Canessa, N. (2021). The neural bases of social and abstract concepts. *Brain Structure and Function*, 226(5), 1459-1472.

Barsalou, L. W. (2008). Grounded cognition. *Annual Review of Psychology*, 59, 617-645.

Binder, J. R., Conant, L. L., Humphries, C. J., Fernandino, L., Simons, S. B., Aguilar, M., & Desai, R. H. (2016). Toward a brain-based componential semantic representation. *Cognitive Neuropsychology*, 33(3-4), 130-174.

Borghi, A. M., Binkofski, F., Castelfranchi, C., Cimatti, F., Scorolli, C., & Tummolini, L. (2017). The challenge of abstract concepts. *Psychological Bulletin*, 143(3), 263-292.

Chalmers, D. J. (1995). Facing up to the problem of consciousness. *Journal of Consciousness Studies*, 2(3), 200-219.

Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. *Behavioral and Brain Sciences*, 36(3), 181-204.

Connell, L., Lynott, D., & Banks, B. (2018). Interoception: The forgotten modality in perceptual grounding of abstract and concrete concepts. *Philosophical Transactions of the Royal Society B*, 373(1752), 20170143.

Danan, H. (2025a). Abstraction is all you need. *Working Paper*.

Danan, H. (2025b). Recursive abstraction. *Working Paper*.

Danan, H. (2025c). Consciousness as emergent abstraction. *Working Paper*.

Fischer, J., Mikhael, J. G., Tenenbaum, J. B., & Kanwisher, N. (2016). Functional neuroanatomy of intuitive physical inference. *Proceedings of the National Academy of Sciences*, 113(34), E5072-E5081.

Friston, K. (2010). The free-energy principle: A unified brain theory? *Nature Reviews Neuroscience*, 11(2), 127-138.

Kelley, W. M., Macrae, C. N., Wyland, C. L., Caglar, S., Inati, S., & Heatherton, T. F. (2002). Finding the self? An event-related fMRI study. *Journal of Cognitive Neuroscience*, 14(5), 785-794.

Kousta, S. T., Vigliocco, G., Vinson, D. P., Andrews, M., & Del Campo, E. (2011). The representation of abstract words: Why emotion matters. *Journal of Experimental Psychology: General*, 140(1), 14-34.

Lakoff, G., & Johnson, M. (1999). *Philosophy in the flesh: The embodied mind and its challenge to Western thought*. Basic Books.

Lewis, M. (2011). The origins and uses of self-awareness or the mental representation of me. *Consciousness and Cognition*, 20(1), 120-129.

Markus, H. R., & Kitayama, S. (1991). Culture and the self: Implications for cognition, emotion, and motivation. *Psychological Review*, 98(2), 224-253.

Northoff, G., Heinzel, A., de Greck, M., Bermpohl, F., Dobrowolny, H., & Panksepp, J. (2006). Self-referential processing in our brain—A meta-analysis of imaging studies on the self. *NeuroImage*, 31(1), 440-457.

Paivio, A. (1986). *Mental representations: A dual coding approach*. Oxford University Press.

Rochat, P. (1998). Self-perception and action in infancy. *Experimental Brain Research*, 123(1-2), 102-109.

Seth, A. K. (2013). Interoceptive inference, emotion, and the embodied self. *Trends in Cognitive Sciences*, 17(11), 565-573.

Seth, A. K., & Friston, K. J. (2016). Active interoceptive inference and the emotional brain. *Philosophical Transactions of the Royal Society B*, 371(1708), 20160007.

Vigliocco, G., Kousta, S. T., Della Rosa, P. A., Vinson, D. P., Tettamanti, M., Devlin, J. T., & Cappa, S. F. (2014). The neural representation of abstract words: The role of emotion. *Cerebral Cortex*, 24(7), 1767-1777.

Villani, C., Lugli, L., Liuzza, M. T., & Borghi, A. M. (2019). Varieties of abstract concepts and their multiple dimensions. *Language and Cognition*, 11(3), 403-430.

Wolpert, D. M., & Ghahramani, Z. (2000). Computational principles of movement neuroscience. *Nature Neuroscience*, 3(11), 1212-1217.

-----

*Working draft. For discussion and critique.*
