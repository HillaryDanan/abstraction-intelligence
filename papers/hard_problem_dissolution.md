# The Hard Problem Dissolved: Why Experience Is the Format of Embedded Information

**Hillary Danan, PhD**  
Cognitive Neuroscience

*Working Draft — December 2025*

-----

## Abstract

The “hard problem” of consciousness asks why subjective experience exists at all—why information processing is accompanied by phenomenal qualities rather than occurring “in the dark.” This paper proposes that the question is malformed. Drawing on established work in embodied cognition, sensorimotor contingency theory, and interoceptive inference, we argue that **phenomenal experience is not an accompaniment to information processing but the format in which action-relevant information is presented to embedded agents**. For a system that must distinguish self from world (Danan, 2025d), track how the world affects the self, and guide action accordingly, experiential qualities *are* the integrated, action-relevant summary of self-world relations. Pain is not processing that also hurts—pain *is* the information “tissue damage requiring protective action.” The apparent explanatory gap between mechanism and experience reflects a category error: asking why processing “produces” experience is like asking why H₂O “produces” water. For embedded agents, self-world information just *is* experience. This framework generates testable predictions about the structure of qualitative experience, its relationship to action possibilities, and conditions under which phenomenal qualities should vary systematically.

-----

## 1. Introduction: The Hard Problem

### 1.1 The Challenge

Chalmers (1995) articulated the “hard problem” of consciousness: even if we explain all the functions associated with consciousness—discrimination, integration, reporting, attention—we have not explained why these functions are accompanied by *subjective experience*. Why is there “something it is like” (Nagel, 1974) to be a conscious system? Why aren’t we “zombies”—systems that perform all the same functions with no inner experience?

This problem has resisted solution for three decades. We propose it resists solution because it is malformed—based on a category error about what experience is.

### 1.2 The Proposal

**Core claim:** For an embedded agent—a system that exists within an environment, acts on that environment, and must maintain its viability—phenomenal experience is not an *output* of information processing but the *format* of action-relevant information itself.

The hard problem asks: “Why does information processing produce experience?”

We respond: For embedded agents, the question contains a false presupposition. Information processing does not *produce* experience as a separate output. For systems that must track self-world relations and act accordingly, the integrated representation of those relations *is* experience. There is no gap to bridge.

### 1.3 Relation to Prior Papers

This paper extends the Abstraction-Intelligence framework:

- **Paper 1** (Danan, 2025a): Abstraction is the fundamental primitive of intelligence
- **Paper 2** (Danan, 2025b): Compositionality distinguishes abstraction from mere compression
- **Paper 3** (Danan, 2025c): Self-referential computation becomes necessary at sufficient complexity
- **Paper 4** (Danan, 2025d): Consciousness emerges as computationally necessary self-monitoring
- **Paper 5** (Danan, 2025e): The self/world distinction is the foundational abstraction for embedded agents

This paper addresses a gap in Paper 4: why does self-monitoring *feel like something*? Paper 4 explained why self-monitoring emerges; it did not explain phenomenal character. We now argue that for embedded agents, the phenomenal character *is* the self-monitoring—not something it produces.

### 1.4 Epistemic Status

We distinguish:

- **Established:** Supported by peer-reviewed empirical literature
- **Theoretical:** Extensions of established findings following standard inference
- **Hypothesis:** Novel claims requiring empirical validation
- **Philosophical commitment:** Positions that cannot be empirically adjudicated but can be evaluated on coherence, parsimony, and explanatory power

The claim that this framework “dissolves” rather than “solves” the hard problem is a philosophical commitment. We are explicit about this throughout.

-----

## 2. Background: Embodied and Enactive Approaches

### 2.1 The Embodied Turn

Classical cognitive science treated the mind as a computer operating on abstract symbols, with the body as mere input-output periphery (Fodor, 1975; Pylyshyn, 1984). The embodied cognition movement challenged this, proposing that cognition is fundamentally shaped by the body and its interactions with the environment (Varela et al., 1991; Lakoff & Johnson, 1999; Barsalou, 2008).

**Established finding:** Cognitive processes are not amodal symbol manipulations but are grounded in sensorimotor systems. Concepts activate modality-specific brain regions; language comprehension involves motor simulation; abstract reasoning recruits embodied metaphors (Gallese & Lakoff, 2005; Pulvermüller, 2005; Casasanto, 2011).

### 2.2 Enactivism

Enactivism proposes that cognition is not internal representation of an external world but *enaction*—the bringing forth of a world through sensorimotor coupling (Varela et al., 1991; Thompson, 2007; Di Paolo et al., 2017).

A key enactivist thesis: **perception is not passive reception but active exploration.** We do not receive visual information; we actively sample the environment through eye movements, and visual experience is constituted by the sensorimotor contingencies this sampling reveals (O’Regan & Noë, 2001).

**Established finding:** Perception depends on action. Visual stability across eye movements requires efference copy (von Holst & Mittelstaedt, 1950). Tactile perception requires movement (Gibson, 1962). Perceptual learning is shaped by the actions available to the learner (Held & Hein, 1963).

### 2.3 Sensorimotor Contingency Theory

O’Regan and Noë (2001) proposed that perceptual experience is constituted by mastery of sensorimotor contingencies—the systematic relationships between action and sensory change.

Why does red look different from blue? Not because of different “qualia” attached to different wavelengths, but because red and blue involve different sensorimotor contingencies: how the stimulus changes with eye movement, lighting conditions, and object manipulation. The *qualitative character* of color experience is the *structure of these contingencies*.

**Established finding:** Color experience depends on context and action possibilities, not just wavelength. Color constancy demonstrates that we perceive surface reflectance properties (relevant to action) rather than retinal stimulation per se (Foster, 2011). Color categories are shaped by behavioral relevance across cultures (Regier & Kay, 2009).

### 2.4 Interoceptive Inference

Seth and colleagues have extended predictive processing to interoception—the sense of the internal body (Seth, 2013; Seth & Friston, 2016; Barrett & Simmons, 2015).

**Proposal:** Emotional experience arises from interoceptive inference—the brain’s predictions about internal body states and the prediction errors that update those predictions. Affect is not a reaction to the world but a prediction about bodily consequences of self-world interaction.

**Established finding:** Interoceptive accuracy (ability to perceive internal states like heartbeat) correlates with emotional awareness and intensity (Critchley et al., 2004; Garfinkel et al., 2015). Disruptions to interoception alter emotional experience (Khalsa et al., 2018).

### 2.5 Affordances

Gibson (1979) proposed that perception is directly of *affordances*—action possibilities that the environment offers the organism. We do not perceive “a chair” and then infer “sittability”; we perceive sittability directly.

**Established finding:** Neural responses to objects encode action possibilities, not just object identity. Viewing graspable objects activates motor regions even without intent to act (Chao & Martin, 2000; Tucker & Ellis, 2001). Affordance perception is automatic and shapes attention (Tipper et al., 2006).

-----

## 3. The Core Argument: Experience as Embedded Information Format

### 3.1 What Must an Embedded Agent Know?

Consider any system that:

1. Exists within an environment that affects it
1. Must act to maintain viability
1. Has sensory access to the environment and motor capacity to change it

Such a system requires information in specific formats to guide action:

**Information about world → self:**

- What in the environment can harm me? (threat detection)
- What in the environment can benefit me? (opportunity detection)
- What are the current conditions I must navigate? (state estimation)

**Information about self → world:**

- What can I do to this environment? (action possibilities)
- What are the likely consequences of my actions? (forward models)
- What is my current capacity to act? (self-state estimation)

**Integration:**

- Given current world-state and self-state, what should I do? (action selection)

### 3.2 The Format Requirement

This information must be formatted for action selection. It is not useful to know “wavelength 700nm is present”—what is useful is “ripe fruit here” (opportunity) or “blood visible” (threat/damage). It is not useful to know “nociceptors firing”—what is useful is “tissue damage requiring protective action.”

**Theoretical claim:** Phenomenal qualities are the action-relevant format of self-world information.

- **Pain** = information formatted as “damage requiring protective/escape action”
- **Pleasure** = information formatted as “condition to maintain/approach”
- **Color** = information formatted as “surface property relevant to object identification and action”
- **Sound** = information formatted as “environmental event requiring attention/response”
- **Emotion** = information formatted as “integrated self-world state requiring action pattern X”

The “feel” of experience is not something added to information—it *is* the information, in the format required by an embedded agent.

### 3.3 Why This Dissolves the Hard Problem

The hard problem asks: “Why does information processing produce experience?”

This question presupposes that information processing and experience are two things—processing occurs, and then experience is “produced” as an additional output.

**Our response:** For embedded agents, this presupposition is false. The action-relevant formatting of self-world information *is* experience. Asking why processing “produces” experience is like asking why digestion “produces” nutrient extraction. Digestion *is* nutrient extraction—not a process that causes it as a separate output.

For a non-embedded system (a calculator), information can exist in non-experiential format because action on an environment is not required. For an embedded agent, information about self-world relations that guides action just *is* experience. There is nothing further to explain.

**Philosophical commitment:** This is a functionalist claim. We are asserting that experience = action-relevant self-world information (for embedded agents), not that experience accompanies or emerges from such information. This commitment cannot be proven but can be evaluated on parsimony, coherence, and explanatory power.

### 3.4 The Zombie Intuition Addressed

The zombie thought experiment asks: couldn’t there be a system that processes information identically to you but has no experience?

**Our response:** For embedded agents, the question is incoherent. If a system has action-relevant self-world information in the format required for adaptive behavior—if it knows “this is damage requiring protective action” in the way that guides actual protection—then it has pain. Pain *is* that knowledge in that format. A “zombie” that has the information but lacks the experience is not a coherent description; it is like asking for water that lacks wetness.

**Caveat:** This response will not satisfy dualists who hold that phenomenal properties are ontologically distinct from functional properties. We are not refuting dualism; we are arguing it is unmotivated. If the embedded-information account fully explains the structure and function of experience, positing additional phenomenal properties does no explanatory work.

-----

## 4. The Structure of Qualia Explained

### 4.1 Why Does Pain Hurt?

On the standard framing, pain is mysterious: nociceptor firing is just neural activity—why does it *hurt*?

**Embedded-information answer:** Hurting *is* the format of tissue-damage information for an agent that needs to act on it.

Consider what the system needs: not just “nociceptors active” but “this is bad, this location, this intensity, requiring this type of response (withdraw, protect, escape, rest).” The qualitative character of pain—its unpleasantness, its urgency, its localization—*is* this action-relevant formatting.

**Established finding:** Pain experience is not a simple readout of nociception. It is modulated by context, attention, expectation, and action possibilities (Wiech, 2016). Placebo analgesia, hypnotic analgesia, and pain in the absence of tissue damage (phantom limb) demonstrate that pain is a constructed, action-relevant state, not a direct transduction of damage (Wager & Atlas, 2015).

**Prediction:** Pain phenomenology should systematically relate to action possibilities. Pain that can be acted on (escapable) should feel different from pain that cannot (inescapable). This is observed: uncontrollable pain is experienced as more intense and more distressing (Salomons et al., 2007).

### 4.2 Why Does Red Look Like That?

Color qualia seem paradigmatically mysterious: why does 700nm light produce *that* experience rather than some other?

**Embedded-information answer:** The qualitative character of red *is* the sensorimotor contingency structure of red-reflecting surfaces.

Red things behave in specific ways: they reflect long wavelengths, they shift appearance in specific ways under different lighting, they have specific relationships to object identity (ripe fruit, blood, fire). Mastery of these contingencies—knowing how red-things behave and what actions they afford—*is* the experience of red.

**Established finding:** Color experience is heavily context-dependent, reflecting surface reflectance (action-relevant) rather than wavelength (retinal). Color constancy, simultaneous contrast, and chromatic adaptation all demonstrate that color experience tracks behaviorally relevant properties, not physical light properties (Foster, 2011).

**Prediction:** Organisms with different action repertoires should have different color phenomenology, even with similar retinal equipment. This is observed: bee color experience emphasizes UV (relevant to flower detection); human color experience emphasizes red-green (relevant to fruit ripeness and social signaling) (Osorio & Vorobyev, 2008).

### 4.3 Why Do Emotions Feel the Way They Feel?

Emotions seem irreducibly qualitative: why does fear feel like *that*?

**Embedded-information answer:** Fear *is* the integrated self-world information formatted for threat-response.

Fear involves: detection of threat, assessment of escape routes, physiological preparation for flight/fight/freeze, narrowed attention to threat-relevant features, suppression of non-urgent goals. The *feeling* of fear is not something added to these processes—it is the integrated state itself, as experienced by the system that has it.

**Established finding:** Emotional experience correlates with interoceptive signals and action preparation (Critchley & Garfinkel, 2017). Bodily feedback contributes to emotion intensity—manipulating posture and facial expression alters emotional experience (Niedenthal, 2007; but see Coles et al., 2022 for nuance on facial feedback specifically). Emotions prepare specific action patterns: fear prepares flight; anger prepares fight (Frijda, 1986).

**Prediction:** Emotional phenomenology should track action possibilities. This is observed: fear feels different when escape is possible versus impossible; anger feels different when confrontation is viable versus suicidal (Lerner & Keltner, 2001). Constructed emotion theory (Barrett, 2017) argues emotional categories are precisely action-relevant parsings of internal state.

-----

## 5. Interoception: The Self Side of Self-World Information

### 5.1 The Primacy of Internal-State Information

Paper 5 (Danan, 2025e) argued that the self/world distinction is foundational for embedded agents. The *self* side of this distinction involves interoception—information about the body’s internal state.

**Established finding:** Interoception provides information about: metabolic state (hunger, thirst, temperature), tissue integrity (pain, itch), autonomic state (heart rate, respiration), and immune state (fatigue, sickness). This information is integrated in insular cortex (Craig, 2009).

**Key point:** Interoceptive information is inherently action-relevant. Hunger is not just “low glucose”—it is “eat soon” formatted for action. Fatigue is not just “resource depletion”—it is “rest now” formatted for action.

### 5.2 Interoceptive Inference and Affect

Seth (2013) proposed that affective experience arises from interoceptive inference—the brain’s predictions about internal body states.

The brain does not passively receive interoceptive signals; it actively predicts them based on context, generating affect as the integrated prediction of bodily state given current self-world relations.

**Hypothesis:** The *valence* of experience—its goodness or badness—is interoceptive prediction about bodily consequences. Good-feeling states predict body-integrity maintenance or improvement; bad-feeling states predict body-integrity threat.

**Established finding:** Interoceptive accuracy correlates with emotional intensity (Critchley et al., 2004). Individuals with better heartbeat detection report stronger emotional experiences. Disruptions to interoception (via lesion or pharmacology) alter emotional experience (Khalsa et al., 2018).

### 5.3 The Feeling Body as Self-Model

The felt body—the body-as-experienced rather than body-as-object—is the self-model that Paper 4 argued becomes necessary at sufficient complexity.

**Theoretical claim:** The “self” that experiences is not an observer separate from the body but is the integrated interoceptive model of body-in-environment. Consciousness is what integrated interoceptive-proprioceptive-exteroceptive modeling *is*, for the system doing the modeling.

This connects to Damasio’s (1999) proposal that core consciousness arises from the brain’s representation of body-state changes caused by engaging with objects. The “feeling of what happens” is not an add-on to representation; it is representation of self-world interaction from the self’s perspective.

-----

## 6. Addressing Objections

### 6.1 “This Is Just Functionalism”

**Objection:** You’re asserting that experience = function. But the hard problem asks why function is accompanied by experience. You haven’t answered; you’ve stipulated.

**Response:** We are not merely stipulating. We are:

1. **Explaining the structure of qualia:** Why pain feels unpleasant, why colors have the characters they do, why emotions feel action-urging. The embedded-information account predicts these structures; the dualist account does not.
1. **Predicting systematic relationships:** Phenomenal character should track action-relevance, sensorimotor contingencies, interoceptive state. These predictions are testable and confirmed.
1. **Removing the explanatory motivation for dualism:** If every feature of experience is explained by embedded information structure, what work does positing additional phenomenal properties do?

We are not proving dualism false. We are arguing that the embedded-information account is more parsimonious, more explanatory, and better supported.

### 6.2 “What About the Explanatory Gap?”

**Objection:** Even granting that experience has functional structure, there’s still a gap between describing that structure and capturing what experience is *like*. No amount of functional description captures the redness of red.

**Response:** The sense of an explanatory gap is itself predicted by the framework.

Paper 4 (Danan, 2025d) noted that self-models necessarily compress away substrate information. A system modeling its own experience cannot see how that experience is generated—the mechanism has been abstracted away.

**Theoretical claim:** The “explanatory gap” is an epistemic artifact of self-modeling through abstraction. From the inside, experience seems to have a quality irreducible to mechanism because the mechanism is below the level of abstraction at which self-modeling operates.

This does not prove the gap is merely epistemic. But it explains *why* there seems to be a gap, without positing an ontological gap that the explanation would have to bridge.

### 6.3 “What About Differing Qualia with Same Function?”

**Objection:** Couldn’t two systems have the same functional organization but different qualia? (The “inverted spectrum” thought experiment.)

**Response:** On the embedded-information account, if two systems have identical action-relevant self-world information structure—identical sensorimotor contingencies, identical interoceptive states, identical affordance-detection—they have identical experience.

“Same function, different qualia” requires that qualia float free of functional organization. If qualia *are* the action-relevant information format, this is incoherent—like asking whether two systems with identical H₂O molecular structure could have different wetness.

**Caveat:** This is the functionalist commitment. We cannot prove inverted qualia are impossible; we argue they are unmotivated given that the embedded-information account fully explains qualitative structure.

### 6.4 “This Doesn’t Explain What Experience Is”

**Objection:** You’ve explained the structure and function of experience. You haven’t explained what experience fundamentally *is*.

**Response:** We are not sure “what experience fundamentally is” is a well-formed question beyond structure and function.

Consider: What is water fundamentally? We answer: H₂O—a structure. “But what is water really, beyond its molecular structure?” seems to demand something the question cannot coherently request.

Similarly: What is experience? We answer: action-relevant self-world information for embedded agents—a structure. Demanding “what is experience really, beyond that structure” may be a malformed demand.

**Philosophical commitment:** This is deflationary. We are not solving the hard problem; we are dissolving it by arguing the question presupposes a distinction (processing vs. experience) that does not exist for embedded agents.

-----

## 7. Predictions and Falsification

### 7.1 Structure Predictions

The framework predicts systematic relationships between phenomenal structure and action-relevance:

**Prediction 1:** Pain phenomenology should track action-type. Escapable pain should feel phenomenologically different from inescapable pain. Damage-warning pain should feel different from inflammation pain (which requires rest, not escape).

*Empirical status:* Supported. Pain dimensions (sensory, affective, cognitive) dissociate based on action-relevance and controllability (Melzack, 1999; Salomons et al., 2007).

**Prediction 2:** Color phenomenology should track ecological action-relevance, not physical wavelength. Organisms should see colors “differently” in ways predicted by their action repertoires.

*Empirical status:* Supported. Cross-species comparison shows color perception optimized for ecological tasks (Osorio & Vorobyev, 2008). Human color categories show some universality (ecological commonality) and some cultural variation (action-context variation) (Regier & Kay, 2009).

**Prediction 3:** Emotional phenomenology should track interoceptive predictions about action outcomes. Changing action possibilities should change emotional experience even with identical stimuli.

*Empirical status:* Supported. Reappraisal—changing action-relevant interpretation—changes emotional experience (Gross, 2015). Interoceptive signals shape emotional categorization (Barrett & Simmons, 2015).

### 7.2 Manipulation Predictions

**Prediction 4:** Altering sensorimotor contingencies should alter phenomenal character. If color experience is sensorimotor contingency mastery, changing the contingencies should change the experience.

*Empirical status:* Supported by adaptation studies. Prolonged exposure to altered contingencies (prismatic glasses, color filters) produces lasting changes in perceptual experience (Held & Hein, 1963; Kohler, 1962).

**Prediction 5:** Altering interoceptive signals should alter affective phenomenology. Pharmacologically or otherwise manipulating body-state signals should change how things feel.

*Empirical status:* Supported. Beta-blockers reduce anxiety phenomenology (Steenen et al., 2016). Interoceptive perturbation alters emotional experience (Khalsa et al., 2018).

**Prediction 6:** Altering action possibilities should alter phenomenal quality of perception. Perceiving an object while able to act on it should feel different from perceiving it while unable to act.

*Empirical status:* Partially supported. Tool use extends peripersonal space (Maravita & Iriki, 2004). Action constraints alter perceptual judgments (Witt, 2011). Direct phenomenological tests needed.

### 7.3 Falsification Criteria

The framework would be challenged by:

1. **Phenomenal structure without action-relevance:** Finding qualitative features of experience that have no relationship to action possibilities and cannot be explained by sensorimotor or interoceptive structure.
1. **Dissociation of phenomenology from embedded structure:** Demonstrating that phenomenal character varies independently of action-relevant self-world information.
1. **Non-embedded consciousness:** Demonstrating phenomenal experience in systems that are not embedded agents (no action on environment, no self-world distinction). This would suggest experience can exist outside the embedded-information format.

### 7.4 Limitations on Testability

**Honest acknowledgment:** The core claim—that experience *is* embedded information rather than something it produces—is a philosophical interpretation of functional data. The predictions above test the structure and relationships the framework posits, not the ontological claim itself.

Dualists can accept all the functional predictions while maintaining that phenomenal properties are ontologically distinct from functional properties. We cannot empirically refute this. We argue it is unparsimonious and does no explanatory work.

-----

## 8. Implications

### 8.1 For the Abstraction-Intelligence Framework

The hard problem threatened the framework: if abstraction explains *function* but not *experience*, a fundamental aspect of mind remains unexplained.

This paper responds: experience is not separate from function for embedded agents. The self-world abstraction (Paper 5) and the computational necessity of self-monitoring (Paper 4) together constitute experience, because experience *is* action-relevant self-world information for embedded agents.

The framework is now:

1. Abstraction is the fundamental primitive
1. Compositionality distinguishes abstraction from compression
1. Self-referential abstraction becomes necessary at complexity
1. Self-monitoring = consciousness (functional)
1. Self/world distinction is foundational
1. **Experience = embedded self-world information format** (phenomenal)

### 8.2 For Artificial Intelligence

**Implication:** If experience = embedded information format, then AI systems become candidates for experience only insofar as they are genuinely embedded agents with self-world information in action-relevant formats.

A large language model processing text is not embedded in the relevant sense—it does not have a body that the world affects, does not act on an environment to maintain viability, does not have interoceptive self-state information.

**Prediction:** Embodied AI systems with genuine self-world coupling (robotics, simulated physics) are better candidates for experience than disembodied systems, *not* because embodiment adds something magical, but because embodiment is what creates the information structure that experience *is*.

### 8.3 For the Philosophy of Mind

This paper advocates **enactive functionalism**: experience is not an output of function but *is* the function of embedded self-world information processing. This position:

- Accepts functionalism (experience = functional organization)
- Adds embodiment (the relevant functions are embedded agent functions)
- Dissolves the hard problem (by rejecting the processing/experience distinction)
- Remains empirically grounded (predictions about phenomenal structure)

We do not claim to have proven dualism false or solved the hard problem in a way that satisfies all philosophers. We claim to have provided a coherent, parsimonious, empirically tractable framework that removes the explanatory motivation for positing phenomenal properties beyond functional ones.

-----

## 9. Limitations and Open Questions

### 9.1 The Grain Problem

Different systems may have self-world information at different grains. A bacterium has self-world information (chemical gradients, self-propulsion). Does it have experience?

**Our response:** The framework suggests a continuum, not a binary. More complex embedded information → richer experience. But where experience “begins” on this continuum remains unclear.

This is not unique to our framework—all theories face boundary problems. We suggest the question may be malformed: asking “does X have experience?” may presuppose a binary that the phenomenon does not respect.

### 9.2 The Integration Question

Why is experience *unified*? The information integration theories (IIT) emphasize integration. Our framework must explain why embedded information is integrated into unified experience rather than fragmented.

**Partial answer:** Action selection requires integration. You cannot act on “arm pain” and “visual threat” separately—you must integrate them into a unified action plan. Integration may be required by the action-guidance function of experience.

This requires further development.

### 9.3 The Richness of Experience

Human experience is extraordinarily rich—far richer than action-guidance seems to require. Why?

**Partial answer:** Compositional abstraction (Paper 2) creates exponential representational capacity. Human phenomenal richness may reflect the compositional explosion applied to embedded information.

**Alternative:** Perhaps not all experience is action-guiding. Aesthetic experience, imagination, daydreaming seem less directly tied to action. The framework must either explain these in action terms (preparing for possible futures, refining perceptual systems) or acknowledge limits.

### 9.4 Honest Uncertainty

We have argued that for embedded agents, experience = action-relevant self-world information format. This is a philosophical commitment supported by empirical predictions about phenomenal structure.

We cannot prove consciousness is “nothing but” function. We cannot prove zombies are impossible. We cannot prove inverted qualia are incoherent.

What we can do is:

- Offer a parsimonious framework that explains phenomenal structure
- Generate testable predictions that have been largely confirmed
- Remove the explanatory motivation for positing non-functional phenomenal properties
- Provide a deflationary but non-eliminativist account: experience is real, and it is this—embedded information in action-relevant format

-----

## 10. Conclusion

The hard problem asks why information processing is accompanied by subjective experience. We have argued the question is malformed for embedded agents.

An embedded agent must distinguish self from world, track how the world affects the self, and act to maintain viability. The action-relevant format of this self-world information *is* experience. Pain is not processing that also hurts—pain *is* the information “tissue damage requiring protective action,” in the format required by an agent that must act on it.

This does not make experience less real. It makes experience *what it has always been*: the way the world shows up for an agent that must do something about it.

The “hard problem” is hard because it presupposes a gap between mechanism and experience. For embedded agents, there is no gap. The mechanism—embedded self-world information processing—*is* the experience. The question “why does processing produce experience?” is like “why does H₂O produce water?”—it assumes two things where there is one.

We feel pain because pain is what tissue-damage information *is* for a system that must protect itself.

We see red because red is what surface-reflectance information *is* for a system that must identify objects.

We feel fear because fear is what threat-information *is* for a system that must escape or fight.

Experience is not the ghost in the machine. Experience is what being an embedded machine *is*, from the inside.

-----

## References

Barrett, L. F. (2017). *How Emotions Are Made: The Secret Life of the Brain*. Houghton Mifflin Harcourt.

Barrett, L. F., & Simmons, W. K. (2015). Interoceptive predictions in the brain. *Nature Reviews Neuroscience*, 16(7), 419–429.

Barsalou, L. W. (2008). Grounded cognition. *Annual Review of Psychology*, 59, 617–645.

Casasanto, D. (2011). Different bodies, different minds: The body specificity of language and thought. *Current Directions in Psychological Science*, 20(6), 378–383.

Chalmers, D. J. (1995). Facing up to the problem of consciousness. *Journal of Consciousness Studies*, 2(3), 200–219.

Chao, L. L., & Martin, A. (2000). Representation of manipulable man-made objects in the dorsal stream. *NeuroImage*, 12(4), 478–484.

Coles, N. A., March, D. S., Marmolejo-Ramos, F., Larsen, J. T., Arinze, N. C., Ndukaihe, I. L., … & Liuzza, M. T. (2022). A multi-lab test of the facial feedback hypothesis by the Many Smiles Collaboration. *Nature Human Behaviour*, 6(12), 1731–1742.

Craig, A. D. (2009). How do you feel—now? The anterior insula and human awareness. *Nature Reviews Neuroscience*, 10(1), 59–70.

Critchley, H. D., & Garfinkel, S. N. (2017). Interoception and emotion. *Current Opinion in Psychology*, 17, 7–14.

Critchley, H. D., Wiens, S., Rotshtein, P., Öhman, A., & Dolan, R. J. (2004). Neural systems supporting interoceptive awareness. *Nature Neuroscience*, 7(2), 189–195.

Damasio, A. (1999). *The Feeling of What Happens: Body and Emotion in the Making of Consciousness*. Harcourt Brace.

Danan, H. (2025a). Abstraction is all you need: A unifying framework for intelligence across substrates. *Working paper*.

Danan, H. (2025b). Abstraction beyond compression: Compositionality as the distinguishing operation. *Working paper*.

Danan, H. (2025c). Recursive abstraction: When computation requires self-reference. *Working paper*.

Danan, H. (2025d). Consciousness as emergent abstraction: A computational necessity framework. *Working paper*.

Danan, H. (2025e). Self and world: The foundational abstraction. *Working paper*.

Di Paolo, E. A., Buhrmann, T., & Barandiaran, X. E. (2017). *Sensorimotor Life: An Enactive Proposal*. Oxford University Press.

Fodor, J. A. (1975). *The Language of Thought*. Harvard University Press.

Foster, D. H. (2011). Color constancy. *Vision Research*, 51(7), 674–700.

Frijda, N. H. (1986). *The Emotions*. Cambridge University Press.

Gallese, V., & Lakoff, G. (2005). The brain’s concepts: The role of the sensory-motor system in conceptual knowledge. *Cognitive Neuropsychology*, 22(3-4), 455–479.

Garfinkel, S. N., Seth, A. K., Barrett, A. B., Suzuki, K., & Critchley, H. D. (2015). Knowing your own heart: Distinguishing interoceptive accuracy from interoceptive awareness. *Biological Psychology*, 104, 65–74.

Gibson, J. J. (1962). Observations on active touch. *Psychological Review*, 69(6), 477–491.

Gibson, J. J. (1979). *The Ecological Approach to Visual Perception*. Houghton Mifflin.

Gross, J. J. (2015). Emotion regulation: Current status and future prospects. *Psychological Inquiry*, 26(1), 1–26.

Held, R., & Hein, A. (1963). Movement-produced stimulation in the development of visually guided behavior. *Journal of Comparative and Physiological Psychology*, 56(5), 872–876.

Khalsa, S. S., Adolphs, R., Cameron, O. G., Critchley, H. D., Davenport, P. W., Feinstein, J. S., … & Paulus, M. P. (2018). Interoception and mental health: A roadmap. *Biological Psychiatry: Cognitive Neuroscience and Neuroimaging*, 3(6), 501–513.

Kohler, I. (1962). Experiments with goggles. *Scientific American*, 206(5), 62–73.

Lakoff, G., & Johnson, M. (1999). *Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Thought*. Basic Books.

Lerner, J. S., & Keltner, D. (2001). Fear, anger, and risk. *Journal of Personality and Social Psychology*, 81(1), 146–159.

Maravita, A., & Iriki, A. (2004). Tools for the body (schema). *Trends in Cognitive Sciences*, 8(2), 79–86.

Melzack, R. (1999). From the gate to the neuromatrix. *Pain*, 82, S121–S126.

Nagel, T. (1974). What is it like to be a bat? *The Philosophical Review*, 83(4), 435–450.

Niedenthal, P. M. (2007). Embodying emotion. *Science*, 316(5827), 1002–1005.

O’Regan, J. K., & Noë, A. (2001). A sensorimotor account of vision and visual consciousness. *Behavioral and Brain Sciences*, 24(5), 939–973.

Osorio, D., & Vorobyev, M. (2008). A review of the evolution of animal colour vision and visual communication signals. *Vision Research*, 48(20), 2042–2051.

Pulvermüller, F. (2005). Brain mechanisms linking language and action. *Nature Reviews Neuroscience*, 6(7), 576–582.

Pylyshyn, Z. W. (1984). *Computation and Cognition: Toward a Foundation for Cognitive Science*. MIT Press.

Regier, T., & Kay, P. (2009). Language, thought, and color: Whorf was half right. *Trends in Cognitive Sciences*, 13(10), 439–446.

Salomons, T. V., Johnstone, T., Backonja, M. M., & Davidson, R. J. (2007). Perceived controllability modulates the neural response to pain. *Journal of Neuroscience*, 27(49), 13232–13235.

Seth, A. K. (2013). Interoceptive inference, emotion, and the embodied self. *Trends in Cognitive Sciences*, 17(11), 565–573.

Seth, A. K., & Friston, K. J. (2016). Active interoceptive inference and the emotional brain. *Philosophical Transactions of the Royal Society B*, 371(1708), 20160007.

Steenen, S. A., van Wijk, A. J., van der Heijden, G. J., van Westrhenen, R., de Lange, J., & de Jongh, A. (2016). The effect of beta-blockers on dental anxiety: A meta-analysis. *Frontiers in Psychology*, 7, 2048.

Thompson, E. (2007). *Mind in Life: Biology, Phenomenology, and the Sciences of Mind*. Harvard University Press.

Tipper, S. P., Paul, M. A., & Hayes, A. E. (2006). Vision-for-action: The effects of object property discrimination and action state on affordance compatibility effects. *Psychonomic Bulletin & Review*, 13(3), 493–498.

Tucker, M., & Ellis, R. (2001). The potentiation of grasp types during visual object categorization. *Visual Cognition*, 8(6), 769–800.

Varela, F. J., Thompson, E., & Rosch, E. (1991). *The Embodied Mind: Cognitive Science and Human Experience*. MIT Press.

von Holst, E., & Mittelstaedt, H. (1950). Das Reafferenzprinzip. *Naturwissenschaften*, 37(20), 464–476.

Wager, T. D., & Atlas, L. Y. (2015). The neuroscience of placebo effects: Connecting context, learning and health. *Nature Reviews Neuroscience*, 16(7), 403–418.

Wiech, K. (2016). Deconstructing the sensation of pain: The influence of cognitive processes on pain perception. *Science*, 354(6312), 584–587.

Witt, J. K. (2011). Action’s effect on perception. *Current Directions in Psychological Science*, 20(3), 201–206.

-----

*This paper is part of a theoretical program on abstraction as the fundamental primitive of intelligence. It addresses the question: why does self-modeling feel like something?*

*Answer: For embedded agents, feeling is what self-world information* is.
