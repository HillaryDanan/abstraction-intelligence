# Prediction Requires Abstraction

## On the Priority of Representational Formation over Predictive Operation

**Hillary Danan, PhD**

*Working Draft — Paper 12 in the Abstraction Primitive Hypothesis series*

-----

## Abstract

Predictive processing frameworks propose that prediction is the fundamental operation of cognition—that brains are essentially prediction machines minimizing surprise. This paper argues that while predictive processing provides powerful explanations of cognitive dynamics, prediction cannot be the *primitive* operation because prediction presupposes representational content. To predict that X will occur, a system must already possess: (1) a representation of X, (2) a representation of futurity or temporal modality, and (3) the compositional capacity to combine them. These representational capacities are products of abstraction. We argue that abstraction is therefore logically and computationally prior to prediction—abstraction creates the representational currency that prediction operates on. We address the co-constitution objection (that abstraction and prediction emerge together), acknowledging its force while arguing that even co-constitutive accounts must grant abstraction explanatory priority: prediction explains *which* abstractions are selected, but the capacity to form abstractions at all is what prediction selects over. We derive testable predictions distinguishing abstraction-first from prediction-first accounts and identify empirical signatures that would falsify our position.

-----

## 1. Introduction

The predictive processing framework has emerged as one of the most influential unifying theories in cognitive science (Friston, 2010; Clark, 2013; Hohwy, 2013). On this view, the brain is fundamentally a prediction engine: it continuously generates predictions about incoming sensory signals and updates its internal models based on prediction error. This elegant framework has been applied to perception (Rao & Ballard, 1999), action (Friston et al., 2010), attention (Feldman & Friston, 2010), and increasingly to higher cognition, emotion, and consciousness (Seth & Friston, 2016).

Given this success, predictive processing represents the most serious alternative to the Abstraction Primitive Hypothesis (APH)—the claim that abstraction, not prediction, is the fundamental operation from which other cognitive capacities derive (Papers 1–11 in this series). If prediction is truly primitive, then abstraction might be better understood as a downstream consequence of predictive dynamics rather than a foundational operation.

This paper directly addresses this challenge. We argue that prediction, despite its explanatory power, cannot be the primitive operation of cognition because prediction *presupposes* the representational content that abstraction provides. Our argument proceeds as follows:

1. **The content requirement**: Prediction requires something to predict—representational content with semantic structure.
1. **The composition requirement**: Predictions combine representations (event + futurity), requiring compositional capacity—the signature feature that distinguishes abstraction from mere compression (see Paper 2).
1. **The priority claim**: Abstraction is the operation that creates representational content; prediction operates on that content. Abstraction is constrained as a specific operation distinct from both input and downstream operations (see Paper 3)—and prediction is a downstream operation.
1. **The co-constitution response**: Even if abstraction and prediction are developmentally intertwined, abstraction retains explanatory priority.

We acknowledge throughout what is established finding versus working hypothesis, and we derive predictions that would falsify our position.

-----

## 2. Predictive Processing: Core Claims

### 2.1 The Framework

Predictive processing proposes that the brain implements hierarchical generative models that continuously predict sensory input (Friston, 2010). Perception occurs not through bottom-up feature extraction but through top-down prediction, with ascending signals carrying only *prediction error*—the discrepancy between expected and actual input (Rao & Ballard, 1999).

**Established findings supporting predictive processing:**

- Predictive coding accounts parsimoniously explain a range of perceptual phenomena including repetition suppression, mismatch negativity, and binocular rivalry (Summerfield & de Lange, 2014).
- Neural responses are systematically modulated by expectation, with expected stimuli producing reduced neural activity consistent with prediction error minimization (Todorovic et al., 2011).
- The hierarchical structure of cortical processing is consistent with hierarchical predictive models (Bastos et al., 2012).

These findings establish that prediction is *a* fundamental operation of neural systems. The question is whether prediction is *the* fundamental operation—whether it is primitive.

### 2.2 The Primitivity Claim

Strong versions of predictive processing make prediction primitive. Friston’s free-energy principle proposes that all adaptive behavior can be understood as minimizing variational free energy—a bound on surprise (Friston, 2010). On this view, perception, action, learning, and even the structure of organisms emerge from this single imperative.

Clark (2013) articulates the vision clearly: “Brains… are essentially prediction machines” that “minimize prediction error” through “a unified theoretical framework” (pp. 181-182).

*This is the claim we contest*—not the explanatory utility of prediction, but its status as the foundational primitive.

-----

## 3. The Content Requirement: Prediction Presupposes Representation

### 3.1 The Logical Structure of Prediction

Consider what it means to predict. A prediction has the logical form:

> *The system represents that X will obtain at time t+n*

This requires:

1. **A representation of X**—the content being predicted
1. **A representation of temporal modality**—the futurity operator that distinguishes prediction from mere representation
1. **A compositional operation**—combining X with the futurity operator

Each of these requirements involves abstraction.

### 3.2 The Representation of X

To predict “the ball will fall,” a system must represent *ball* and *fall* as distinct, recombinable elements. This is abstraction: the extraction of invariant structure from variable instances.

**Established finding**: Representations are not given but constructed. Developmental research demonstrates that even basic object concepts require abstraction from sensory experience—infants develop object permanence, category boundaries, and causal schemas through extended interaction with the world (Carey, 2009; Spelke & Kinzler, 2007).

**Established finding**: Neural representations of objects and events are distributed, compositional, and abstract—they generalize across surface features (Quiroga et al., 2005; Kriegeskorte et al., 2008).

The predictive processing framework *uses* these representations but does not explain their origin at the computational level. Prediction error can select *among* representations (favoring those that predict well), but something must generate the representational candidates in the first place.

### 3.3 The Representation of Futurity

Predictions are tensed—they concern what *will* occur, not what *is* occurring. This requires a representation of temporal modality: the abstract distinction between present and future.

**Established finding**: Temporal cognition involves abstracting relational structure. The representation of before/after, duration, and temporal perspective requires extracting invariant temporal relations across variable content (Friedman, 1990; Suddendorf & Corballis, 2007).

**Established finding**: Future-oriented cognition (prospection) recruits many of the same neural systems as memory (Schacter et al., 2007), suggesting that both involve constructive combination of abstracted elements—not retrieval or prediction of raw sensory streams.

The futurity operator *is* an abstraction—a formal distinction extracted from the flow of experience. A system cannot predict without possessing this abstraction.

### 3.4 The Composition Requirement

Predictions combine content (X) with modality (future). This is compositional structure: the systematic combination of representational elements to generate new representations.

**Established finding**: Human cognition exhibits systematicity and productivity—the ability to understand and generate novel combinations of familiar elements (Fodor & Pylyshyn, 1988). Someone who understands “the cat chases the mouse” can understand “the mouse chases the cat” without additional learning.

**Established finding**: Compositional structure requires representations that factor into recombinable parts (Lake et al., 2017; Marcus, 2001). This factorization is itself a form of abstraction—extracting the compositional structure from holistic patterns.

Prediction inherits its compositional structure from the representations it operates on. The question is: where does this compositional structure come from?

**Working hypothesis (APH claim)**: Abstraction is the operation that creates compositional representational structure. Compression reduces; abstraction composes. This is what makes abstraction suitable as a cognitive primitive—it generates the representational capacity that other operations presuppose.

This compositional criterion is central to the APH framework. Paper 2 in this series (*Abstraction Beyond Compression*; Danan, 2025b) develops the argument that compositionality is precisely what distinguishes abstraction from mere compression. Rate-distortion theory, the information bottleneck, and minimum description length all describe mappings that preserve relevant information while reducing complexity—but they do not inherently produce representations that *combine* to form new representations. A maximally compressed representation of a specific input is optimized for that input; it does not yield reusable components that transfer to novel contexts. Abstraction, by contrast, produces compositional building blocks—and prediction requires exactly this compositional structure to combine content representations with temporal operators.

The implication for the present argument: predictive processing requires compositional representations, and compositionality is the signature of abstraction rather than compression. Prediction therefore presupposes not just *some* representational capacity, but specifically *abstractive* capacity—the capacity to form composable symbols.

-----

## 4. The Priority Argument

### 4.1 Logical Priority

The preceding analysis establishes that prediction presupposes:

- Representational content (abstracted from sensory input)
- Temporal modality (an abstracted relational category)
- Compositional structure (systematically factorable representations)

These are products of abstraction. Therefore, abstraction is *logically prior* to prediction—prediction cannot occur without abstraction having already occurred.

This is not a claim about temporal sequence but about explanatory dependency. Even if abstraction and prediction occur simultaneously in mature systems, the explanatory arrow runs from abstraction to prediction: abstraction explains what prediction operates on.

### 4.2 Computational Priority

Consider what a prediction engine requires computationally:

1. **A hypothesis space**: The set of possible states to predict over
1. **A generative model**: Structure mapping from latent states to observations
1. **An update rule**: How prediction errors revise the model

The hypothesis space and generative model are composed of representations. Where do these come from?

**Predictive processing answer**: They emerge through hierarchical learning driven by prediction error minimization.

**Our response**: This is correct but incomplete. Learning which representations are useful (via prediction error) requires a space of possible representations to select over. The capacity to *form* representations—to abstract invariant structure from variable input—is prior to the capacity to *select* representations based on predictive utility.

Prediction is a selection pressure; abstraction is what is selected. Natural selection requires organisms to select over; predictive selection requires abstractions to select over.

### 4.3 The Vocabulary/Grammar Distinction

Consider an analogy to language. Prediction error can select which *sentences* are uttered (those that communicate effectively). But this selection presupposes:

- A vocabulary (abstracted word representations)
- A grammar (compositional rules for combining words)

Predictive utility might shape which sentences are used, but the capacity for language—the representational vocabulary and compositional grammar—is prior.

Similarly, prediction error can select which *representations* are maintained. But this selection presupposes:

- A representational vocabulary (abstracted concepts)
- Compositional structure (rules for combining concepts)

Abstraction provides the vocabulary and grammar; prediction provides selection pressure over their use.

-----

## 5. The Co-Constitution Objection

### 5.1 The Objection Stated

The most sophisticated response from predictive processing is that abstraction and prediction are *co-constitutive*—they emerge together through developmental dynamics, with neither strictly prior (see Clark, 2016, on “embodied prediction”).

On this view:

- Early prediction operates over low-level sensory representations
- Prediction error drives the formation of more abstract representations
- More abstract representations enable more abstract predictions
- This bootstrapping process means abstraction and prediction cannot be separated

This is a serious objection that we partially accept.

### 5.2 What Co-Constitution Concedes

Even granting co-constitution, abstraction retains explanatory priority in two senses:

**First**, at any given moment in the bootstrapping process, the predictions being made presuppose the abstractions already formed. The current prediction operates on the current representational vocabulary. Future abstraction may be shaped by current prediction error, but current prediction presupposes current abstraction.

**Second**, co-constitution still requires explaining *what abstraction contributes* that prediction cannot provide alone. If prediction error shapes representation, *what* is being shaped? The answer is: the abstraction capacity—the ability to extract invariant structure, form compositional representations, and generalize beyond training instances.

The co-constitution account can explain *which* abstractions are learned. It cannot explain the capacity for abstraction itself.

### 5.3 The Capacity vs. Content Distinction

This reveals a crucial distinction:

- **Abstraction capacity**: The ability to form invariant, compositional, generalizable representations
- **Abstraction content**: The specific representations a system has formed

Predictive processing may powerfully explain abstraction *content*—why we have the specific concepts we have, shaped by predictive utility. But abstraction *capacity*—the computational machinery that makes concept formation possible—is presupposed by the predictive account.

**Working hypothesis**: Abstraction capacity is the primitive. Abstraction content is shaped by many factors, including predictive utility. The APH claims priority for capacity, not content.

This capacity/content distinction connects to a broader constraint on the APH developed in Paper 3 (*Abstraction Constrained*; Danan, 2025c). That paper addresses the vacuity objection—the concern that if all cognition derives from abstraction, the concept explains nothing. The response is that abstraction is a *specific* operation: the conversion of attended information into manipulable, composable symbols. It is distinct from input operations (perception, attention) that provide raw material, and from downstream operations (memory, learning, reasoning, decision-making, action) that operate *on* abstractions. Abstraction is the central transformation—not synonymous with cognition, but the operation that creates the representational currency other operations trade in.

This constraint matters for the prediction debate. Prediction is a *downstream operation*—it operates on representations that already exist. The question “what is primitive?” is the question “what creates the representational format that downstream operations require?” The APH answer: abstraction. Predictive processing can explain how abstraction content is refined, but the capacity for abstraction—the ability to form composable symbols at all—is what prediction presupposes.

-----

## 6. Empirical Predictions and Falsification Criteria

A theory’s value lies in its testable predictions. If abstraction is prior to prediction, we should observe specific empirical signatures. If prediction is prior, we should observe different signatures.

### 6.1 Predictions Favoring Abstraction Priority

**Prediction 1: Abstraction deficits should impair prediction more than prediction deficits impair abstraction.**

If abstraction is prior, then damage to abstraction capacity should produce widespread predictive failures (no representational content to predict with). But damage to predictive mechanisms should leave abstraction capacity intact (content can still be formed, just not used predictively).

*Relevant evidence*: Patients with semantic dementia show profound loss of conceptual knowledge (abstraction loss) with relatively preserved prediction mechanisms for non-semantic domains (Patterson et al., 2007). Conversely, patients with cerebellar damage show impaired prediction timing with relatively preserved semantic abstraction (Ivry & Spencer, 2004).

*Falsification*: If predictive impairments produced global abstraction failures, this would favor prediction priority.

**Prediction 2: Compositional generalization should be dissociable from prediction accuracy.**

If abstraction (particularly compositional structure) is prior to prediction, then systems can possess compositional representations without necessarily using them for accurate prediction. Conversely, systems might achieve accurate prediction without compositional structure (through holistic pattern matching).

*Relevant evidence*: Large language models achieve remarkable prediction accuracy (low perplexity) while showing systematic failures in compositional generalization (Lake & Baroni, 2018; Kim & Linzen, 2020). This dissociation suggests prediction and compositional abstraction are separable capacities.

*Falsification*: If prediction accuracy and compositional generalization were perfectly correlated across systems, this would challenge the dissociability of abstraction and prediction.

**Prediction 3: Abstract representation should emerge in systems not trained for prediction.**

If abstraction capacity is prior to prediction, then abstraction should be achievable through operations other than prediction error minimization—including unsupervised clustering, compression, and analogy.

*Relevant evidence*: Humans form abstract categories through exemplar exposure without explicit prediction tasks (Ashby & Maddox, 2005). Abstraction occurs through analogy, comparison, and structural alignment independent of predictive context (Gentner & Markman, 1997).

*Falsification*: If abstraction *only* occurred through predictive dynamics, this would support prediction priority.

**Prediction 4: Developmental deprivation of abstraction-scaffolding input should produce abstraction deficits even when sensorimotor experience remains available.**

If abstraction is prior and requires specific developmental inputs—language exposure, social interaction, symbolic scaffolding—then depriving these inputs should devastate abstraction capacity. Critically, if prediction were primary and could bootstrap abstraction, then children with intact sensorimotor experience but impoverished linguistic/social input should eventually develop abstraction through predictive learning from physical interaction alone. The prediction-first account implies that sensorimotor prediction, given sufficient time and experience, should be able to bootstrap higher-order abstraction.

*Relevant evidence*: The Bucharest Early Intervention Project (BEIP) provides a tragic natural experiment testing this prediction (Nelson, Fox, & Zeanah, 2014). Children raised in Romanian orphanages experienced severe deprivation of language exposure, contingent social interaction, and scaffolded symbolic communication, while retaining basic sensorimotor interaction with their physical environment. Findings include:

- Profound and lasting deficits in language acquisition, with institutionalized children showing vocabulary and grammatical development far below age-matched norms (Windsor et al., 2011)
- Significantly reduced IQ and impaired capacity for abstract reasoning (Nelson et al., 2007)
- Deficits in executive function and working memory—capacities requiring the manipulation of abstract representations (Bos et al., 2009)
- Critical period effects: early intervention (foster care placement before approximately 24 months) enabled partial cognitive recovery; later placement showed markedly limited recovery, suggesting abstraction capacity has developmental windows that sensorimotor experience alone cannot reopen (Nelson et al., 2007)

*Interpretation*: Institutionalized children had years of sensorimotor experience—interacting with objects, experiencing physical contingencies, navigating their environment. On a prediction-first account, this extensive opportunity for sensorimotor prediction should have provided sufficient raw material for bootstrapping abstract representation through predictive learning. It did not. The specific and devastating deficits were concentrated in language and higher cognition—the domains most dependent on compositional, symbolic abstraction. The developmental bottleneck was abstraction-scaffolding input (language, contingent social interaction, symbolic communication), not prediction opportunity per se.

*Limitations*: This interpretation assumes that sensorimotor experience enables sensorimotor prediction, and that the BEIP children’s physical environment interaction constituted such prediction opportunity. The studies did not directly measure predictive processing capacity. The argument is inferential: if prediction alone could bootstrap abstraction, it should have done so given years of physical interaction; its failure to do so suggests abstraction requires its own developmental inputs that prediction cannot substitute for.

*Falsification*: If children with severely impoverished linguistic/social input but intact sensorimotor experience showed normal abstraction development (even if delayed), this would suggest prediction can bootstrap abstraction—challenging abstraction priority.

### 6.2 Predictions Distinguishing APH from Alternative Frameworks

**Prediction 5: Abstraction stage should constrain prediction sophistication.**

The APH posits developmental stages of abstraction (pattern extraction → symbol formation → recursive composition → self-reference). If abstraction is prior, then predictive sophistication should be constrained by abstraction stage—a system at stage 2 cannot make predictions requiring stage 3 representations.

*Relevant evidence*: Children’s predictive capacities track abstraction stages. Pre-operational children fail predictions requiring relational reasoning even when the predictive task is simple (Halford et al., 1998). Theory of mind predictions emerge only after relevant representational capacities (Wellman et al., 2001).

*Falsification*: If predictive sophistication exceeded abstraction stage systematically, this would challenge abstraction priority.

**Prediction 6: Scaling should differentially affect abstraction vs. prediction.**

If abstraction is prior and computationally distinct from prediction, then scaling dimensions (parameters, data, compute) should differentially affect abstraction and prediction capacities.

*Relevant evidence*: In large language models, scaling improves prediction (perplexity) more consistently than abstraction (compositional generalization, relational reasoning) (Wei et al., 2022; Webb et al., 2023). This suggests abstraction and prediction have different computational requirements.

*Falsification*: If scaling improved abstraction and prediction uniformly, this would suggest they are not computationally distinct.

### 6.3 Strong Falsification Criteria for APH

We state explicitly what would falsify abstraction priority:

1. **Demonstrating prediction without representation**: A system that makes successful predictions without any representational content—predicting sensory streams directly without extracting invariant structure. (Note: This may be conceptually impossible, which would strengthen our claim.)
1. **Demonstrating that abstraction *requires* prediction error**: If abstraction could be proven to only occur through prediction error minimization, with no alternative pathways, this would support prediction priority.
1. **Demonstrating systematic dissociation in the wrong direction**: If predictive impairment reliably caused abstraction failure, while abstraction impairment left prediction intact, this would favor prediction priority.

-----

## 7. Integrating Predictive Processing within the APH Framework

### 7.1 Prediction as Abstraction Application

We propose that prediction is best understood as *the application of abstraction to temporal reasoning*. Specifically:

- Abstraction extracts invariant structure → yields representations
- Temporal abstraction extracts before/after/future relations → yields temporal operators
- Compositional abstraction combines representations with temporal operators → yields predictions

On this view, prediction is not a competitor to abstraction but a *species* of abstraction—abstraction applied to the temporal domain.

### 7.2 Prediction Error as Selection Pressure

We fully accept that prediction error plays a crucial role in shaping abstraction content. The abstractions a system maintains are those useful for navigating its environment—and predictive utility is a major component of usefulness.

But selection pressure presupposes variation to select over. Prediction error selects among possible abstractions; the capacity to generate those abstractions is what the APH addresses.

### 7.3 A Unified Account

The integrated view:

|**Operation**   |**Function**                                        |**Relationship**                         |
|----------------|----------------------------------------------------|-----------------------------------------|
|Abstraction     |Creates representational content                    |Primitive                                |
|Prediction      |Applies representations to future-directed inference|Derived (species of abstraction)         |
|Prediction Error|Selects among representations                       |Selection pressure on abstraction content|
|Learning        |Updates abstractions based on error                 |Mechanism for abstraction refinement     |

This preserves the insights of predictive processing while locating prediction in a larger framework with abstraction as primitive.

-----

## 8. Implications

### 8.1 For Cognitive Science

If abstraction is prior to prediction, then cognitive science should attend not just to how organisms predict but to *how they generate the representational vocabulary they predict with*. The abstraction problem is prior to the prediction problem.

This suggests renewed attention to:

- Concept formation and category learning
- Compositional structure acquisition
- The development of abstract relational reasoning
- Cross-domain abstraction and analogical mapping

### 8.2 For Artificial Intelligence

Current AI systems excel at prediction (language models achieve remarkable next-token prediction) while showing systematic failures in abstraction (compositional generalization, relational reasoning, causal understanding).

If abstraction is prior, this explains the pattern: optimizing prediction does not automatically yield abstraction. Architectures that directly support abstraction—factorized representations, explicit compositional structure, relational processing—may be necessary complements to predictive training.

**Working hypothesis**: Scaling prediction (more parameters, more data) will not resolve abstraction limitations. Architectural innovations that directly support abstraction capacity are required.

### 8.3 For Consciousness Studies

The APH proposes that consciousness emerges when abstraction is applied reflexively—when a system abstracts over its own processes (Papers 6–8). If abstraction is prior to prediction, then predictive accounts of consciousness (Seth & Friston, 2016) should be understood as identifying *one application* of self-referential abstraction rather than consciousness’s fundamental basis.

-----

## 9. Limitations and Open Questions

### 9.1 Acknowledged Limitations

**The definition of abstraction remains to be fully formalized.** While Paper 3 constrains what abstraction is and is not, a complete computational formalization is ongoing work.

**The boundary between abstraction and compression is not fully resolved.** Some compression schemes discover compositional structure; the precise conditions distinguishing “mere compression” from “genuine abstraction” require further specification.

**The temporal relationship between abstraction and prediction in development is complex.** We have argued for logical and explanatory priority, not necessarily temporal priority in all cases.

### 9.2 Open Questions

1. What minimal computational architecture supports abstraction capacity?
1. Can abstraction capacity be quantified and compared across systems?
1. What is the relationship between abstraction capacity and information-theoretic quantities?
1. Are there fundamental limits on abstraction capacity analogous to limits on prediction?

-----

## 10. Conclusion

Predictive processing provides a powerful framework for understanding cognitive dynamics. But prediction cannot be the primitive operation of cognition because prediction presupposes what abstraction provides: representational content with compositional structure.

To predict that X will occur, a system must possess:

- A representation of X (abstracted content)
- A representation of futurity (abstracted temporal relation)
- The capacity to compose them (compositional structure)

These are products of abstraction. Prediction operates on the representational currency that abstraction creates.

We have addressed the co-constitution objection, acknowledging that abstraction content is shaped by predictive utility while maintaining that abstraction *capacity* is explanatorily prior. Prediction is the selection pressure; abstraction is what is selected over.

The argument generates testable predictions: abstraction deficits should impair prediction more than vice versa; compositional generalization should be dissociable from prediction accuracy; abstraction should be achievable through non-predictive pathways; developmental deprivation of abstraction-scaffolding input should devastate abstraction even when sensorimotor prediction remains possible. We have stated falsification criteria explicitly.

If this analysis is correct, then abstraction is not one cognitive operation among many but the operation that creates the representational foundation on which other operations—including prediction—depend. Prediction is powerful. Abstraction is prior.

-----

## References

Ashby, F. G., & Maddox, W. T. (2005). Human category learning. *Annual Review of Psychology*, 56, 149–178.

Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., & Friston, K. J. (2012). Canonical microcircuits for predictive coding. *Neuron*, 76(4), 695–711.

Bos, K. J., Fox, N. A., Zeanah, C. H., & Nelson, C. A. (2009). Effects of early psychosocial deprivation on the development of memory and executive function. *Frontiers in Behavioral Neuroscience*, 3, 16.

Carey, S. (2009). *The Origin of Concepts*. Oxford University Press.

Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. *Behavioral and Brain Sciences*, 36(3), 181–204.

Clark, A. (2016). *Surfing Uncertainty: Prediction, Action, and the Embodied Mind*. Oxford University Press.

Danan, H. (2025b). Abstraction beyond compression: Compositionality as the distinguishing operation. *Working paper*.

Danan, H. (2025c). Abstraction constrained: What the primitive is and is not. *Working paper*.

Feldman, H., & Friston, K. (2010). Attention, uncertainty, and free-energy. *Frontiers in Human Neuroscience*, 4, 215.

Fodor, J. A., & Pylyshyn, Z. W. (1988). Connectionism and cognitive architecture: A critical analysis. *Cognition*, 28(1–2), 3–71.

Friedman, W. J. (1990). *About Time: Inventing the Fourth Dimension*. MIT Press.

Friston, K. (2010). The free-energy principle: A unified brain theory? *Nature Reviews Neuroscience*, 11(2), 127–138.

Friston, K. J., Daunizeau, J., Kilner, J., & Kiebel, S. J. (2010). Action and behavior: A free-energy formulation. *Biological Cybernetics*, 102(3), 227–260.

Gentner, D., & Markman, A. B. (1997). Structure mapping in analogy and similarity. *American Psychologist*, 52(1), 45–56.

Halford, G. S., Wilson, W. H., & Phillips, S. (1998). Processing capacity defined by relational complexity: Implications for comparative, developmental, and cognitive psychology. *Behavioral and Brain Sciences*, 21(6), 803–831.

Hohwy, J. (2013). *The Predictive Mind*. Oxford University Press.

Ivry, R. B., & Spencer, R. M. (2004). The neural representation of time. *Current Opinion in Neurobiology*, 14(2), 225–232.

Kim, N., & Linzen, T. (2020). COGS: A compositional generalization challenge based on semantic interpretation. *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing*, 9087–9105.

Kriegeskorte, N., Mur, M., & Bandettini, P. A. (2008). Representational similarity analysis—connecting the branches of systems neuroscience. *Frontiers in Systems Neuroscience*, 2, 4.

Lake, B. M., & Baroni, M. (2018). Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. *Proceedings of the 35th International Conference on Machine Learning*, 2873–2882.

Lake, B. M., Ullman, T. D., Tenenbaum, J. B., & Gershman, S. J. (2017). Building machines that learn and think like people. *Behavioral and Brain Sciences*, 40, e253.

Marcus, G. F. (2001). *The Algebraic Mind: Integrating Connectionism and Cognitive Science*. MIT Press.

Nelson, C. A., Fox, N. A., & Zeanah, C. H. (2014). *Romania’s Abandoned Children: Deprivation, Brain Development, and the Struggle for Recovery*. Harvard University Press.

Nelson, C. A., Zeanah, C. H., Fox, N. A., Marshall, P. J., Smyke, A. T., & Guthrie, D. (2007). Cognitive recovery in socially deprived young children: The Bucharest Early Intervention Project. *Science*, 318(5858), 1937–1940.

Patterson, K., Nestor, P. J., & Rogers, T. T. (2007). Where do you know what you know? The representation of semantic knowledge in the human brain. *Nature Reviews Neuroscience*, 8(12), 976–987.

Quiroga, R. Q., Reddy, L., Kreiman, G., Koch, C., & Fried, I. (2005). Invariant visual representation by single neurons in the human brain. *Nature*, 435(7045), 1102–1107.

Rao, R. P., & Ballard, D. H. (1999). Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects. *Nature Neuroscience*, 2(1), 79–87.

Schacter, D. L., Addis, D. R., & Buckner, R. L. (2007). Remembering the past to imagine the future: The prospective brain. *Nature Reviews Neuroscience*, 8(9), 657–661.

Seth, A. K., & Friston, K. J. (2016). Active interoceptive inference and the emotional brain. *Philosophical Transactions of the Royal Society B*, 371(1708), 20160007.

Spelke, E. S., & Kinzler, K. D. (2007). Core knowledge. *Developmental Science*, 10(1), 89–96.

Suddendorf, T., & Corballis, M. C. (2007). The evolution of foresight: What is mental time travel, and is it unique to humans? *Behavioral and Brain Sciences*, 30(3), 299–313.

Summerfield, C., & de Lange, F. P. (2014). Expectation in perceptual decision making: Neural and computational mechanisms. *Nature Reviews Neuroscience*, 15(11), 745–756.

Todorovic, A., van Ede, F., Maris, E., & de Lange, F. P. (2011). Prior expectation mediates neural adaptation to repeated sounds in the auditory cortex: An MEG study. *Journal of Neuroscience*, 31(25), 9118–9123.

Webb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language models. *Nature Human Behaviour*, 7, 1526–1541.

Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., … & Fedus, W. (2022). Emergent abilities of large language models. *Transactions on Machine Learning Research*.

Wellman, H. M., Cross, D., & Watson, J. (2001). Meta-analysis of theory-of-mind development: The truth about false belief. *Child Development*, 72(3), 655–684.

Windsor, J., Benigno, J. P., Wing, C. A., Carroll, P. J., Koga, S. F., Nelson, C. A., Fox, N. A., & Zeanah, C. H. (2011). Effect of foster care on young children’s language learning. *Child Development*, 82(4), 1040–1046.

-----

## Acknowledgments

This paper developed through dialogue examining whether prediction could serve as a cognitive primitive alternative to abstraction. The author thanks the many colleagues whose challenges sharpened these arguments.

-----

*“Prediction is powerful. Abstraction is prior.”*
