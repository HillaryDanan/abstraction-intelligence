# Abstraction-Intelligence

A theoretical framework proposing that **abstraction is the fundamental primitive operation underlying intelligence** across biological and artificial substrates.

## Overview

This repository contains working papers developing the **Abstraction Primitive Hypothesis (APH)** — the claim that intelligence, across substrates, is the capacity to form, store, retrieve, and compose abstractions. All other cognitive operations (attention, reasoning, memory, learning) derive from or are implementations of abstraction.

The framework generates testable predictions about learning curves, transfer learning, neural network scaling laws, and the computational conditions under which self-reference and consciousness emerge.

## Core Claims

1. **Abstraction as Primitive**: Abstraction is not one cognitive operation among many — it is the operation from which others derive.
1. **Self-Referential Dynamics**: Abstraction capacity follows growth patterns where the rate of new abstraction formation depends on existing abstractions (mathematically characterized by *e*).
1. **Recursive Self-Modeling**: When a system’s optimal output depends on its own complex internal state, self-referential computation—modeling oneself through abstraction—becomes necessary.
1. **Consciousness as Self-Abstraction**: When abstraction is applied reflexively to a system of sufficient complexity, the result is an integrated self-model — consciousness.
1. **Self/World as Foundational Abstraction**: The distinction between self and not-self is the first abstraction any embedded intelligent system must make — the scaffold upon which all subsequent abstractions build.

## Papers

|Paper                                                                                |Status       |Description                                                                                       |
|-------------------------------------------------------------------------------------|-------------|--------------------------------------------------------------------------------------------------|
|[Abstraction Is All You Need](papers/abstraction_is_all_you_need.md)                 |Working Draft|The general framework: abstraction as the fundamental primitive of intelligence                   |
|[Recursive Abstraction](papers/recursive_abstraction.md)                             |Working Draft|When computation requires self-reference: feedforward vs. feedback vs. self-modeling architectures|
|[Consciousness as Emergent Abstraction](papers/consciousness_emergent_abstraction.md)|Working Draft|Application to consciousness: why self-monitoring becomes computationally necessary               |
|[Self and World](papers/self_world_abstraction.md)                                   |Working Draft|The foundational abstraction: why any embedded intelligence must distinguish self from not-self   |

## Reading Order

1. **Abstraction Is All You Need** — establishes abstraction as primitive
1. **Recursive Abstraction** — establishes when computation must bend back on itself
1. **Consciousness as Emergent Abstraction** — applies the framework to consciousness specifically
1. **Self and World** — grounds the framework in the foundational self/not-self distinction

## Key Predictions

The framework makes falsifiable predictions including:

- Learning curves for hierarchical skills should fit logistic/exponential models with rate parameters correlating to abstraction opportunity
- Transfer learning success should be predicted by shared abstraction structure, not surface similarity
- Neural network scaling should relate to abstraction capacity, not raw parameter count
- Feedforward architectures will show qualitative limits on tasks requiring self-reference, regardless of scale
- A complexity threshold exists above which integrated self-monitoring becomes computationally necessary
- Abstract concepts should organize neurally along a self/world dimension reflecting computational necessity, not arbitrary convention
- Embodied AI systems should develop more robust abstract reasoning than disembodied systems trained on text alone

See individual papers for detailed predictions and falsification criteria.

## Theoretical Context

This work builds on established literature in:

- **Cognitive Science**: Chunking (Miller, 1956; Cowan, 2001), relational complexity (Halford et al., 1998)
- **Machine Learning**: Representation learning (Bengio et al., 2013), attention mechanisms (Vaswani et al., 2017)
- **Control Theory**: Feedback systems (Wiener, 1948), adaptive control (Åström & Wittenmark, 1995)
- **Consciousness Science**: Global Workspace Theory (Baars, 1988), Integrated Information Theory (Tononi, 2004), Predictive Processing (Friston, 2010)
- **Information Theory**: Rate-distortion theory (Shannon, 1948), information bottleneck (Tishby et al., 2000)
- **Embodied Cognition**: Grounded cognition (Barsalou, 2008), enactivism (Varela et al., 1991), interoceptive inference (Seth, 2013)

## Status

These are **working theoretical papers** — hypotheses with testable predictions, not established results. The framework is offered for discussion, critique, and empirical testing.

## Author

**Hillary Danan, PhD**  
Cognitive Neuroscience

## License

MIT

-----

*“Intelligence may be, at root, the capacity to see what can be ignored.”*
