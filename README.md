# Abstraction-Intelligence

**What makes something intelligent?**

The **Abstraction Primitive Hypothesis (APH)**: intelligence emerges from recursive interaction between symbol formation and compositional structure.

---

## The Core Claim

**Abstraction is the recursive process of forming and composing symbols.**

```
    [Raw Input] â†’ [Symbol Formation] â†’ [Symbols] â†’ [Composition] â†’ [Composed Structures]
                         â–²                                              â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [Feedback] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Not symbols alone. Not composition alone. Their **mutual refinement through iteration**.

---

## The Composition Hierarchy

Not all composition is the same.

| Type | Structure | Example |
|------|-----------|---------|
| **3a: Concatenative** | A + B â†’ AB | "blue bird" |
| **3b: Role-filler** | R(x) + S(y) â†’ R(x)S(y) | AGENT(dog) + ACTION(chased) + PATIENT(cat) |
| **3c: Recursive** | A contains [B contains C] | "The dog [that chased the cat [that...]]" |
| **3d: Analogical** | Structure(A) â†’ Structure(B) | atom:nucleus :: solar system:sun |

**Prediction:** Systems show 3a-3b success with 3c-3d failure. Bees do role-filler (waggle dance), not recursion. LLMs degrade faster on recursive depth than role-filler novelty.

---

## Embeddedness

Strong interaction requires **novelty detection**â€”recognizing unfamiliar against a background of familiar.

Novelty is relational. An input isn't novel in itselfâ€”it's novel *to a subject*. This requires:

1. **Persistent self** â†’ accumulated experience ("what's familiar to me")
2. **Self/world distinction** â†’ reference frame for locating novelty
3. **Embeddedness** â†’ what makes persistence and self/world possible

```
Embeddedness â†’ Persistent self â†’ Familiar/unfamiliar distinction â†’ Novelty detection â†’ Pressure to expand primitives â†’ Strong interaction
```

Non-embedded systems can *process* the concept of novelty but cannot *detect* itâ€”there's no accumulated self to whom something could be unfamiliar.

**Five components of embeddedness:**
- Action-consequence contingency
- Feedback closure
- Temporal persistence
- Self-boundary awareness
- Environmental stability

LLMs fail all five. This predicts principled Stage 4 limitations that scaling cannot overcome.

---

## Predictions

| Prediction | Falsification |
|------------|---------------|
| Composition types dissociate (3a-3b vs. 3c-3d) | No differences found |
| Recursive depth degrades faster than role-filler novelty | Identical degradation curves |
| Bees: role-filler yes, recursive no | Bees succeed at recursion |
| Non-embedded systems can't detect novelty | System without persistence shows genuine novelty detection |

---

## Papers

**Core (1â€“9):**

| # | Paper |
|---|-------|
| 1 | [Abstraction Is All You Need](papers/abstraction_is_all_you_need.md) |
| 2 | [The Computational Structure of Abstraction](papers/abstraction_defined.md) |
| 3 | [Abstraction Beyond Compression](papers/abstraction_beyond_compression.md) |
| 4 | [Abstraction Constrained](papers/abstraction_constrained.md) |
| 5 | [Prediction Requires Abstraction](papers/prediction_requires_abstraction.md) |
| 6 | [Recursive Abstraction](papers/recursive_abstraction.md) |
| 7 | [The Developmental Spectrum](papers/abstraction_developmental_spectrum.md) |
| 8 | [Embeddedness and Self/World](papers/embedded_abstraction.md) |
| 9 | [Self and World](papers/self_world_abstraction.md) |

**Extensions (10â€“15):**

| # | Paper |
|---|-------|
| 10 | [Consciousness as Emergent Abstraction](papers/consciousness_emergent_abstraction.md) |
| 11 | [The Hard Problem Reframed](papers/hard_problem_reframed.md) |
| 12 | [Time as Embodied Abstraction](papers/time_embodied_abstraction.md) |
| 13 | [Emotion as Embedded Information](papers/emotion_embedded_information.md) |
| 14 | [Social Dynamics](papers/social_dynamics.md) |
| 15 | [Beyond Large Language Models](papers/beyond_llms.md) |
| 16 | [Dual-Process Theory Reconsidered](papers/dual_process_abstraction.md) |

---

## Empirical Research Program

### ğŸ§  Core Framework
[abstraction-intelligence](https://github.com/HillaryDanan/abstraction-intelligence) Â·
[composition-type-dissociation](https://github.com/HillaryDanan/composition-type-dissociation) Â·
[compositional-abstraction](https://github.com/HillaryDanan/compositional-abstraction) Â·
[compositional-dual-process](https://github.com/HillaryDanan/compositional-dual-process) Â·
[embeddedness-calibration](https://github.com/HillaryDanan/embeddedness-calibration) Â·
[emergent-factorization](https://github.com/HillaryDanan/emergent-factorization) Â·
[reasoning-in-vacuum](https://github.com/HillaryDanan/reasoning-in-vacuum)

### ğŸ”„ Self-Reference
[self-referential-dynamics](https://github.com/HillaryDanan/self-referential-dynamics) Â·
[computational-self-construction](https://github.com/HillaryDanan/computational-self-construction) Â·
[ouroboros-learning](https://github.com/HillaryDanan/ouroboros-learning) Â·
[recursive-reality](https://github.com/HillaryDanan/recursive-reality)

### â±ï¸ Temporal
[TIDE](https://github.com/HillaryDanan/TIDE) Â·
[TIDE-resonance](https://github.com/HillaryDanan/TIDE-resonance) Â·
[TIDE-analysis](https://github.com/HillaryDanan/TIDE-analysis) Â·
[temporal-coherence-llm](https://github.com/HillaryDanan/temporal-coherence-llm) Â·
[temporal-myopia-llm](https://github.com/HillaryDanan/temporal-myopia-llm) Â·
[llm-time-decay](https://github.com/HillaryDanan/llm-time-decay) Â·
[curved-cognition](https://github.com/HillaryDanan/curved-cognition)

### ğŸŒ Embodiment
[embodied-cognition](https://github.com/HillaryDanan/embodied-cognition) Â·
[physical-grounding-llm](https://github.com/HillaryDanan/physical-grounding-llm) Â·
[TERRA-embodied-interpretability](https://github.com/HillaryDanan/TERRA-embodied-interpretability)

### ğŸª Consciousness
[BIND](https://github.com/HillaryDanan/BIND) Â·
[comparative-consciousness-llms](https://github.com/HillaryDanan/comparative-consciousness-llms) Â·
[hexagonal-consciousness-suite](https://github.com/HillaryDanan/hexagonal-consciousness-suite) Â·
[computational-emergence-theory](https://github.com/HillaryDanan/computational-emergence-theory)

### ğŸ‘¥ Social
[reciprocal-mirroring-emergence](https://github.com/HillaryDanan/reciprocal-mirroring-emergence) Â·
[game-theory-trust-suite](https://github.com/HillaryDanan/game-theory-trust-suite) Â·
[trust-calibration-framework](https://github.com/HillaryDanan/trust-calibration-framework)

### ğŸ—£ï¸ Language
[linguistic-dynamics-theory](https://github.com/HillaryDanan/linguistic-dynamics-theory) Â·
[linguistic-memory-framework](https://github.com/HillaryDanan/linguistic-memory-framework) Â·
[cross-linguistic-attention-dynamics](https://github.com/HillaryDanan/cross-linguistic-attention-dynamics) Â·
[benign-violations](https://github.com/HillaryDanan/benign-violations)

### ğŸ”¬ Geometry
[causal-attention-geometry](https://github.com/HillaryDanan/causal-attention-geometry) Â·
[multi-geometric-attention](https://github.com/HillaryDanan/multi-geometric-attention) Â·
[relativistic-interpretability](https://github.com/HillaryDanan/relativistic-interpretability) Â·
[spectral-representations](https://github.com/HillaryDanan/spectral-representations)

### ğŸ§ª LLM Testing
[llm-habituation-patterns](https://github.com/HillaryDanan/llm-habituation-patterns) Â·
[nonlinear-dialogue-dynamics](https://github.com/HillaryDanan/nonlinear-dialogue-dynamics) Â·
[paradox-induced-oscillations](https://github.com/HillaryDanan/paradox-induced-oscillations) Â·
[retroactive-causality](https://github.com/HillaryDanan/retroactive-causality) Â·
[claude-emergence-patterns](https://github.com/HillaryDanan/claude-emergence-patterns)

### ğŸ”§ Architecture
[information-atoms](https://github.com/HillaryDanan/information-atoms) Â·
[hexagonal-vision-research](https://github.com/HillaryDanan/hexagonal-vision-research) Â·
[computational-substrates](https://github.com/HillaryDanan/computational-substrates) Â·
[cognitive-architectures-ai](https://github.com/HillaryDanan/cognitive-architectures-ai)

### ğŸ“Š Tools
[pattern-analyzer](https://github.com/HillaryDanan/pattern-analyzer) Â·
[concrete-overflow-detector](https://github.com/HillaryDanan/concrete-overflow-detector)

---

## Author

**Hillary Danan, PhD** Â· Cognitive Neuroscience

---

*"Abstraction is all you need ;)"*
